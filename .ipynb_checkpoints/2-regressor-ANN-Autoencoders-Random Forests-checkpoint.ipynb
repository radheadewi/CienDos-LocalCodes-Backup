{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eba5be72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.max_columns = None\n",
    "pd.set_option('display.max_rows', 20)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Input\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a1c4cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_regression = pd.read_excel(\"feature-eng-data/regression_dataset.xlsx\")\n",
    "df_regression = df_regression.drop(df_regression.columns[0], axis=1)\n",
    "df_regression = df_regression.drop(\"CalculationType\", axis=1)\n",
    "df_regression = df_regression.drop(\"S1S2TesCO2eEst\", axis=1)\n",
    "df_regression = df_regression.set_index(\"CompanyNumber\")\n",
    "df_regression['SIC'] = df_regression['SIC'].astype('category')\n",
    "df_regression['root_parent'] = df_regression['root_parent'].astype('category')\n",
    "df_regression['parent_2'] = df_regression['parent_2'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a35d2a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = df_regression[[\"SIC\", \"root_parent\", \"parent_2\"]]\n",
    "\n",
    "# Drop the categorcial features\n",
    "df_regression.drop([\"SIC\", \"root_parent\", \"parent_2\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cdb7c82a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 SIC  root_parent parent_2\n",
      "CompanyNumber                             \n",
      "00019457         329            2     32.0\n",
      "00024869        6512           10     65.0\n",
      "00029559         701           12     70.0\n",
      "00030226        1712            2     17.0\n",
      "00033774        2059            2     20.0\n",
      "...              ...          ...      ...\n",
      "SC334329       64202           10     64.0\n",
      "SC367563        8299           13     82.0\n",
      "SC419949       64921           10     64.0\n",
      "SC440783        1011            2     10.0\n",
      "SC578050       46431            6     46.0\n",
      "\n",
      "[765 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "categorical_features_copy = categorical_features.copy()\n",
    "\n",
    "# Convert the \"root_parent\" column to numeric type using cat.codes\n",
    "categorical_features_copy[\"root_parent\"] = categorical_features_copy[\"root_parent\"].cat.codes\n",
    "\n",
    "print(categorical_features_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "4401fd6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AssetsM</th>\n",
       "      <th>TurnoverM</th>\n",
       "      <th>FTE</th>\n",
       "      <th>IR_CO2ePerAssetsM</th>\n",
       "      <th>IR_CO2ePerTurnoverM</th>\n",
       "      <th>IR_CO2ePerFTE</th>\n",
       "      <th>DefraRatio</th>\n",
       "      <th>NormalisedIrCO2ePerAssetsM</th>\n",
       "      <th>NormalisedIrCO2ePerTurnoverM</th>\n",
       "      <th>NormalisedIrCO2ePerFTE</th>\n",
       "      <th>ScoreC1a</th>\n",
       "      <th>ScoreC1t</th>\n",
       "      <th>ScoreC1f</th>\n",
       "      <th>ScoreC2</th>\n",
       "      <th>ScoreC1</th>\n",
       "      <th>MeanTotalGHG</th>\n",
       "      <th>MeanCO2</th>\n",
       "      <th>MeanCH4</th>\n",
       "      <th>MeanN2O</th>\n",
       "      <th>MeanHFC</th>\n",
       "      <th>MeanPFC</th>\n",
       "      <th>MeanNF3</th>\n",
       "      <th>MeanSF6</th>\n",
       "      <th>GHGIntensity</th>\n",
       "      <th>CO2Intensity</th>\n",
       "      <th>PM10</th>\n",
       "      <th>PM25</th>\n",
       "      <th>CO</th>\n",
       "      <th>NMVOC</th>\n",
       "      <th>Benzene</th>\n",
       "      <th>Butadine</th>\n",
       "      <th>EnergyIntensity</th>\n",
       "      <th>Electricity</th>\n",
       "      <th>Petrol/diesel</th>\n",
       "      <th>Natural gas</th>\n",
       "      <th>OtherEenergy</th>\n",
       "      <th>EnergyTotal</th>\n",
       "      <th>MeanTotalGHG_lv2</th>\n",
       "      <th>MeanCO2_lv2</th>\n",
       "      <th>S1S2CO2e</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CompanyNumber</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>00019457</th>\n",
       "      <td>3152.0</td>\n",
       "      <td>603.300000</td>\n",
       "      <td>3152.0</td>\n",
       "      <td>0.060444</td>\n",
       "      <td>0.078988</td>\n",
       "      <td>0.015111</td>\n",
       "      <td>1.3750</td>\n",
       "      <td>88.414665</td>\n",
       "      <td>39.608</td>\n",
       "      <td>7.726939</td>\n",
       "      <td>10</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>122937.8</td>\n",
       "      <td>110754.621875</td>\n",
       "      <td>319.9</td>\n",
       "      <td>5781.643750</td>\n",
       "      <td>5166.559375</td>\n",
       "      <td>410.50625</td>\n",
       "      <td>0.3</td>\n",
       "      <td>504.234375</td>\n",
       "      <td>0.814688</td>\n",
       "      <td>0.724688</td>\n",
       "      <td>42.680938</td>\n",
       "      <td>32.870906</td>\n",
       "      <td>632.933031</td>\n",
       "      <td>409.348156</td>\n",
       "      <td>3.675875</td>\n",
       "      <td>0.593</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1.81</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.83</td>\n",
       "      <td>9.38</td>\n",
       "      <td>12.70</td>\n",
       "      <td>0.160938</td>\n",
       "      <td>0.159688</td>\n",
       "      <td>47.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00024869</th>\n",
       "      <td>1048.0</td>\n",
       "      <td>486.000000</td>\n",
       "      <td>1048.0</td>\n",
       "      <td>0.253968</td>\n",
       "      <td>0.954733</td>\n",
       "      <td>0.442748</td>\n",
       "      <td>0.0375</td>\n",
       "      <td>88.414665</td>\n",
       "      <td>39.608</td>\n",
       "      <td>7.726939</td>\n",
       "      <td>10</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>305.1</td>\n",
       "      <td>268.003125</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.946875</td>\n",
       "      <td>35.025000</td>\n",
       "      <td>0.08125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032344</td>\n",
       "      <td>0.027031</td>\n",
       "      <td>2.050844</td>\n",
       "      <td>0.366812</td>\n",
       "      <td>0.015906</td>\n",
       "      <td>0.003</td>\n",
       "      <td>6.2</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>269.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00029559</th>\n",
       "      <td>76060.0</td>\n",
       "      <td>291.200000</td>\n",
       "      <td>76060.0</td>\n",
       "      <td>516.260563</td>\n",
       "      <td>755.762887</td>\n",
       "      <td>2.891494</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>88.414665</td>\n",
       "      <td>39.608</td>\n",
       "      <td>7.726939</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2288.1</td>\n",
       "      <td>2144.109375</td>\n",
       "      <td>9.1</td>\n",
       "      <td>10.868750</td>\n",
       "      <td>100.643750</td>\n",
       "      <td>0.11875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.209375</td>\n",
       "      <td>0.022500</td>\n",
       "      <td>0.020938</td>\n",
       "      <td>0.372188</td>\n",
       "      <td>0.322406</td>\n",
       "      <td>22.857313</td>\n",
       "      <td>4.384531</td>\n",
       "      <td>0.180562</td>\n",
       "      <td>0.039</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.88</td>\n",
       "      <td>1.12</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2.25</td>\n",
       "      <td>0.044375</td>\n",
       "      <td>0.041875</td>\n",
       "      <td>219927.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00030226</th>\n",
       "      <td>584.0</td>\n",
       "      <td>104.600000</td>\n",
       "      <td>584.0</td>\n",
       "      <td>473.260870</td>\n",
       "      <td>373.200000</td>\n",
       "      <td>67.099315</td>\n",
       "      <td>6.6250</td>\n",
       "      <td>88.414665</td>\n",
       "      <td>39.608</td>\n",
       "      <td>7.726939</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>122937.8</td>\n",
       "      <td>110754.621875</td>\n",
       "      <td>319.9</td>\n",
       "      <td>5781.643750</td>\n",
       "      <td>5166.559375</td>\n",
       "      <td>410.50625</td>\n",
       "      <td>0.3</td>\n",
       "      <td>504.234375</td>\n",
       "      <td>0.814688</td>\n",
       "      <td>0.724688</td>\n",
       "      <td>42.680938</td>\n",
       "      <td>32.870906</td>\n",
       "      <td>632.933031</td>\n",
       "      <td>409.348156</td>\n",
       "      <td>3.675875</td>\n",
       "      <td>0.593</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1.81</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.83</td>\n",
       "      <td>9.38</td>\n",
       "      <td>12.70</td>\n",
       "      <td>1.729687</td>\n",
       "      <td>1.721250</td>\n",
       "      <td>39186.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00033774</th>\n",
       "      <td>4017.0</td>\n",
       "      <td>15700.000000</td>\n",
       "      <td>4017.0</td>\n",
       "      <td>1866.017132</td>\n",
       "      <td>319.124586</td>\n",
       "      <td>1247.263132</td>\n",
       "      <td>3.8750</td>\n",
       "      <td>88.414665</td>\n",
       "      <td>39.608</td>\n",
       "      <td>7.726939</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>122937.8</td>\n",
       "      <td>110754.621875</td>\n",
       "      <td>319.9</td>\n",
       "      <td>5781.643750</td>\n",
       "      <td>5166.559375</td>\n",
       "      <td>410.50625</td>\n",
       "      <td>0.3</td>\n",
       "      <td>504.234375</td>\n",
       "      <td>0.814688</td>\n",
       "      <td>0.724688</td>\n",
       "      <td>42.680938</td>\n",
       "      <td>32.870906</td>\n",
       "      <td>632.933031</td>\n",
       "      <td>409.348156</td>\n",
       "      <td>3.675875</td>\n",
       "      <td>0.593</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1.81</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.83</td>\n",
       "      <td>9.38</td>\n",
       "      <td>12.70</td>\n",
       "      <td>3.748490</td>\n",
       "      <td>2.203646</td>\n",
       "      <td>431311.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SC334329</th>\n",
       "      <td>381.0</td>\n",
       "      <td>37.473996</td>\n",
       "      <td>381.0</td>\n",
       "      <td>61.967019</td>\n",
       "      <td>33.135135</td>\n",
       "      <td>3.217848</td>\n",
       "      <td>0.0375</td>\n",
       "      <td>88.414665</td>\n",
       "      <td>39.608</td>\n",
       "      <td>7.726939</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>305.1</td>\n",
       "      <td>268.003125</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.946875</td>\n",
       "      <td>35.025000</td>\n",
       "      <td>0.08125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032344</td>\n",
       "      <td>0.027031</td>\n",
       "      <td>2.050844</td>\n",
       "      <td>0.366812</td>\n",
       "      <td>0.015906</td>\n",
       "      <td>0.003</td>\n",
       "      <td>6.2</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SC367563</th>\n",
       "      <td>1125.0</td>\n",
       "      <td>108.500000</td>\n",
       "      <td>1125.0</td>\n",
       "      <td>5.116468</td>\n",
       "      <td>25.995413</td>\n",
       "      <td>2.518667</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>88.414665</td>\n",
       "      <td>39.608</td>\n",
       "      <td>7.726939</td>\n",
       "      <td>8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3310.9</td>\n",
       "      <td>3179.271875</td>\n",
       "      <td>10.5</td>\n",
       "      <td>20.143750</td>\n",
       "      <td>100.806250</td>\n",
       "      <td>0.14375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.049375</td>\n",
       "      <td>0.047813</td>\n",
       "      <td>1.115719</td>\n",
       "      <td>0.997531</td>\n",
       "      <td>50.637906</td>\n",
       "      <td>8.058969</td>\n",
       "      <td>0.377531</td>\n",
       "      <td>0.090</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1.44</td>\n",
       "      <td>3.47</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.35</td>\n",
       "      <td>5.69</td>\n",
       "      <td>0.036563</td>\n",
       "      <td>0.034375</td>\n",
       "      <td>2272.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SC419949</th>\n",
       "      <td>0.0</td>\n",
       "      <td>29.375452</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.503251</td>\n",
       "      <td>28.137931</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0375</td>\n",
       "      <td>88.414665</td>\n",
       "      <td>39.608</td>\n",
       "      <td>7.726939</td>\n",
       "      <td>7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.195021</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>305.1</td>\n",
       "      <td>268.003125</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.946875</td>\n",
       "      <td>35.025000</td>\n",
       "      <td>0.08125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032344</td>\n",
       "      <td>0.027031</td>\n",
       "      <td>2.050844</td>\n",
       "      <td>0.366812</td>\n",
       "      <td>0.015906</td>\n",
       "      <td>0.003</td>\n",
       "      <td>6.2</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>771.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SC440783</th>\n",
       "      <td>1330.0</td>\n",
       "      <td>498.237572</td>\n",
       "      <td>1330.0</td>\n",
       "      <td>9889.035686</td>\n",
       "      <td>25.656627</td>\n",
       "      <td>9.606767</td>\n",
       "      <td>2.6250</td>\n",
       "      <td>88.414665</td>\n",
       "      <td>39.608</td>\n",
       "      <td>7.726939</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>122937.8</td>\n",
       "      <td>110754.621875</td>\n",
       "      <td>319.9</td>\n",
       "      <td>5781.643750</td>\n",
       "      <td>5166.559375</td>\n",
       "      <td>410.50625</td>\n",
       "      <td>0.3</td>\n",
       "      <td>504.234375</td>\n",
       "      <td>0.814688</td>\n",
       "      <td>0.724688</td>\n",
       "      <td>42.680938</td>\n",
       "      <td>32.870906</td>\n",
       "      <td>632.933031</td>\n",
       "      <td>409.348156</td>\n",
       "      <td>3.675875</td>\n",
       "      <td>0.593</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1.81</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.83</td>\n",
       "      <td>9.38</td>\n",
       "      <td>12.70</td>\n",
       "      <td>0.518398</td>\n",
       "      <td>0.505039</td>\n",
       "      <td>12715.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SC578050</th>\n",
       "      <td>0.0</td>\n",
       "      <td>99.051884</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.295030</td>\n",
       "      <td>1.242424</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.2500</td>\n",
       "      <td>88.414665</td>\n",
       "      <td>39.608</td>\n",
       "      <td>7.726939</td>\n",
       "      <td>7</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.195021</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>15214.9</td>\n",
       "      <td>12694.615625</td>\n",
       "      <td>46.3</td>\n",
       "      <td>97.940625</td>\n",
       "      <td>2376.128125</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083125</td>\n",
       "      <td>0.070313</td>\n",
       "      <td>4.089688</td>\n",
       "      <td>3.473219</td>\n",
       "      <td>106.895281</td>\n",
       "      <td>86.132250</td>\n",
       "      <td>0.889250</td>\n",
       "      <td>0.241</td>\n",
       "      <td>3.7</td>\n",
       "      <td>2.48</td>\n",
       "      <td>3.52</td>\n",
       "      <td>1.90</td>\n",
       "      <td>1.90</td>\n",
       "      <td>9.74</td>\n",
       "      <td>0.110312</td>\n",
       "      <td>0.099687</td>\n",
       "      <td>123.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>765 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               AssetsM     TurnoverM      FTE  IR_CO2ePerAssetsM  \\\n",
       "CompanyNumber                                                      \n",
       "00019457        3152.0    603.300000   3152.0           0.060444   \n",
       "00024869        1048.0    486.000000   1048.0           0.253968   \n",
       "00029559       76060.0    291.200000  76060.0         516.260563   \n",
       "00030226         584.0    104.600000    584.0         473.260870   \n",
       "00033774        4017.0  15700.000000   4017.0        1866.017132   \n",
       "...                ...           ...      ...                ...   \n",
       "SC334329         381.0     37.473996    381.0          61.967019   \n",
       "SC367563        1125.0    108.500000   1125.0           5.116468   \n",
       "SC419949           0.0     29.375452      0.0          20.503251   \n",
       "SC440783        1330.0    498.237572   1330.0        9889.035686   \n",
       "SC578050           0.0     99.051884      0.0          16.295030   \n",
       "\n",
       "               IR_CO2ePerTurnoverM  IR_CO2ePerFTE  DefraRatio  \\\n",
       "CompanyNumber                                                   \n",
       "00019457                  0.078988       0.015111      1.3750   \n",
       "00024869                  0.954733       0.442748      0.0375   \n",
       "00029559                755.762887       2.891494      0.3750   \n",
       "00030226                373.200000      67.099315      6.6250   \n",
       "00033774                319.124586    1247.263132      3.8750   \n",
       "...                            ...            ...         ...   \n",
       "SC334329                 33.135135       3.217848      0.0375   \n",
       "SC367563                 25.995413       2.518667      0.3750   \n",
       "SC419949                 28.137931       0.000000      0.0375   \n",
       "SC440783                 25.656627       9.606767      2.6250   \n",
       "SC578050                  1.242424       0.000000      1.2500   \n",
       "\n",
       "               NormalisedIrCO2ePerAssetsM  NormalisedIrCO2ePerTurnoverM  \\\n",
       "CompanyNumber                                                             \n",
       "00019457                        88.414665                        39.608   \n",
       "00024869                        88.414665                        39.608   \n",
       "00029559                        88.414665                        39.608   \n",
       "00030226                        88.414665                        39.608   \n",
       "00033774                        88.414665                        39.608   \n",
       "...                                   ...                           ...   \n",
       "SC334329                        88.414665                        39.608   \n",
       "SC367563                        88.414665                        39.608   \n",
       "SC419949                        88.414665                        39.608   \n",
       "SC440783                        88.414665                        39.608   \n",
       "SC578050                        88.414665                        39.608   \n",
       "\n",
       "               NormalisedIrCO2ePerFTE  ScoreC1a  ScoreC1t  ScoreC1f  ScoreC2  \\\n",
       "CompanyNumber                                                                  \n",
       "00019457                     7.726939        10      10.0  9.000000      9.0   \n",
       "00024869                     7.726939        10       9.0  8.000000      6.0   \n",
       "00029559                     7.726939         2       1.0  5.000000      2.0   \n",
       "00030226                     7.726939         2       2.0  2.000000      5.0   \n",
       "00033774                     7.726939         1       2.0  1.000000      2.0   \n",
       "...                               ...       ...       ...       ...      ...   \n",
       "SC334329                     7.726939         5       5.0  5.000000      2.0   \n",
       "SC367563                     7.726939         8       5.0  5.000000      6.0   \n",
       "SC419949                     7.726939         7       5.0  5.195021      2.0   \n",
       "SC440783                     7.726939         1       5.0  3.000000      5.0   \n",
       "SC578050                     7.726939         7       9.0  5.195021      9.0   \n",
       "\n",
       "               ScoreC1  MeanTotalGHG        MeanCO2  MeanCH4      MeanN2O  \\\n",
       "CompanyNumber                                                               \n",
       "00019457           9.0      122937.8  110754.621875    319.9  5781.643750   \n",
       "00024869           9.0         305.1     268.003125      1.0     0.946875   \n",
       "00029559           2.0        2288.1    2144.109375      9.1    10.868750   \n",
       "00030226           2.0      122937.8  110754.621875    319.9  5781.643750   \n",
       "00033774           1.0      122937.8  110754.621875    319.9  5781.643750   \n",
       "...                ...           ...            ...      ...          ...   \n",
       "SC334329           5.0         305.1     268.003125      1.0     0.946875   \n",
       "SC367563           6.0        3310.9    3179.271875     10.5    20.143750   \n",
       "SC419949           6.0         305.1     268.003125      1.0     0.946875   \n",
       "SC440783           3.0      122937.8  110754.621875    319.9  5781.643750   \n",
       "SC578050           8.0       15214.9   12694.615625     46.3    97.940625   \n",
       "\n",
       "                   MeanHFC    MeanPFC  MeanNF3     MeanSF6  GHGIntensity  \\\n",
       "CompanyNumber                                                              \n",
       "00019457       5166.559375  410.50625      0.3  504.234375      0.814688   \n",
       "00024869         35.025000    0.08125      0.0    0.000000      0.000000   \n",
       "00029559        100.643750    0.11875      0.0   23.209375      0.022500   \n",
       "00030226       5166.559375  410.50625      0.3  504.234375      0.814688   \n",
       "00033774       5166.559375  410.50625      0.3  504.234375      0.814688   \n",
       "...                    ...        ...      ...         ...           ...   \n",
       "SC334329         35.025000    0.08125      0.0    0.000000      0.000000   \n",
       "SC367563        100.806250    0.14375      0.0    0.000000      0.049375   \n",
       "SC419949         35.025000    0.08125      0.0    0.000000      0.000000   \n",
       "SC440783       5166.559375  410.50625      0.3  504.234375      0.814688   \n",
       "SC578050       2376.128125    0.00000      0.0    0.000000      0.083125   \n",
       "\n",
       "               CO2Intensity       PM10       PM25          CO       NMVOC  \\\n",
       "CompanyNumber                                                               \n",
       "00019457           0.724688  42.680938  32.870906  632.933031  409.348156   \n",
       "00024869           0.000000   0.032344   0.027031    2.050844    0.366812   \n",
       "00029559           0.020938   0.372188   0.322406   22.857313    4.384531   \n",
       "00030226           0.724688  42.680938  32.870906  632.933031  409.348156   \n",
       "00033774           0.724688  42.680938  32.870906  632.933031  409.348156   \n",
       "...                     ...        ...        ...         ...         ...   \n",
       "SC334329           0.000000   0.032344   0.027031    2.050844    0.366812   \n",
       "SC367563           0.047813   1.115719   0.997531   50.637906    8.058969   \n",
       "SC419949           0.000000   0.032344   0.027031    2.050844    0.366812   \n",
       "SC440783           0.724688  42.680938  32.870906  632.933031  409.348156   \n",
       "SC578050           0.070313   4.089688   3.473219  106.895281   86.132250   \n",
       "\n",
       "                Benzene  Butadine  EnergyIntensity  Electricity  \\\n",
       "CompanyNumber                                                     \n",
       "00019457       3.675875     0.593              2.6         1.81   \n",
       "00024869       0.015906     0.003              6.2         0.78   \n",
       "00029559       0.180562     0.039              1.6         0.88   \n",
       "00030226       3.675875     0.593              2.6         1.81   \n",
       "00033774       3.675875     0.593              2.6         1.81   \n",
       "...                 ...       ...              ...          ...   \n",
       "SC334329       0.015906     0.003              6.2         0.78   \n",
       "SC367563       0.377531     0.090              2.6         1.44   \n",
       "SC419949       0.015906     0.003              6.2         0.78   \n",
       "SC440783       3.675875     0.593              2.6         1.81   \n",
       "SC578050       0.889250     0.241              3.7         2.48   \n",
       "\n",
       "               Petrol/diesel  Natural gas  OtherEenergy  EnergyTotal  \\\n",
       "CompanyNumber                                                          \n",
       "00019457                0.69         0.83          9.38        12.70   \n",
       "00024869                0.17         0.07          0.01         1.03   \n",
       "00029559                1.12         0.17          0.08         2.25   \n",
       "00030226                0.69         0.83          9.38        12.70   \n",
       "00033774                0.69         0.83          9.38        12.70   \n",
       "...                      ...          ...           ...          ...   \n",
       "SC334329                0.17         0.07          0.01         1.03   \n",
       "SC367563                3.47         0.42          0.35         5.69   \n",
       "SC419949                0.17         0.07          0.01         1.03   \n",
       "SC440783                0.69         0.83          9.38        12.70   \n",
       "SC578050                3.52         1.90          1.90         9.74   \n",
       "\n",
       "               MeanTotalGHG_lv2  MeanCO2_lv2   S1S2CO2e  \n",
       "CompanyNumber                                            \n",
       "00019457               0.160938     0.159688      47.63  \n",
       "00024869               0.000000     0.000000     269.00  \n",
       "00029559               0.044375     0.041875  219927.00  \n",
       "00030226               1.729687     1.721250   39186.00  \n",
       "00033774               3.748490     2.203646  431311.00  \n",
       "...                         ...          ...        ...  \n",
       "SC334329               0.000000     0.000000       0.00  \n",
       "SC367563               0.036563     0.034375    2272.20  \n",
       "SC419949               0.000000     0.000000     771.00  \n",
       "SC440783               0.518398     0.505039   12715.00  \n",
       "SC578050               0.110312     0.099687     123.00  \n",
       "\n",
       "[765 rows x 40 columns]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70cc369",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concatenated = pd.concat([categorical_features_copy, df_regression], axis=1)\n",
    "df_concatenated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "865ea0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = df_regression.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c54691e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "normalised_df_regression = scaler.fit_transform(df_regression)\n",
    "S1S2CO2e = normalised_df_regression[:, -1]\n",
    "\n",
    "# drop the label\n",
    "normalised_df_regression = np.delete(normalised_df_regression, -1, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "247e8963",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(765, 39)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalised_df_regression.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8cb6b6be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instances in X: 765\n",
      "Number of instances in X_train: 535\n",
      "Number of instances in X_test: 230\n",
      "Number of instances in X_train and X_test together: 765\n"
     ]
    }
   ],
   "source": [
    "X = normalised_df_regression\n",
    "Y = S1S2CO2e\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, train_size=0.70, test_size=0.30, random_state=0)\n",
    "\n",
    "print('Number of instances in X: {}'.format(np.shape(X)[0]))\n",
    "print('Number of instances in X_train: {}'.format(X_train.shape[0]))\n",
    "print('Number of instances in X_test: {}'.format(X_test.shape[0]))\n",
    "print('Number of instances in X_train and X_test together: {}'.format(X_train.shape[0] + X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "850ca68e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 327us/step\n",
      "Testing accuracy by using r2_score metric: 0.334\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Create a deep learning model\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1))  # Output layer for regression\n",
    "\n",
    "# Step 2: Compile the model\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "# Step 3: Train the model\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=32, verbose=0)\n",
    "\n",
    "# Step 4: Evaluate the model on testing data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Step 5: Calculate R-squared score\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print('Testing accuracy by using r2_score metric: {:.3f}'.format(r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e114d48b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 583us/step\n",
      "3/3 [==============================] - 0s 535us/step\n",
      "3/3 [==============================] - 0s 510us/step\n",
      "3/3 [==============================] - 0s 565us/step\n",
      "3/3 [==============================] - 0s 465us/step\n",
      "3/3 [==============================] - 0s 542us/step\n",
      "3/3 [==============================] - 0s 473us/step\n",
      "3/3 [==============================] - 0s 556us/step\n",
      "3/3 [==============================] - 0s 539us/step\n",
      "3/3 [==============================] - 0s 587us/step\n",
      "10-Fold Cross-Validation RMSE Scores:\n",
      "[0.1660784  0.09619562 0.15004225 0.11319592 0.15559675 0.1176053\n",
      " 0.02799855 0.09956473 0.07161089 0.13359843]\n",
      "Mean RMSE: 0.113\n",
      "Standard Deviation of RMSE: 0.040\n",
      "10-Fold Cross-Validation R2 Scores:\n",
      "[ 0.18690639  0.50066574  0.01193254  0.48589547  0.43472452  0.14739575\n",
      "  0.13682403  0.20159549  0.34739838 -0.06491087]\n",
      "Mean R2: 0.239\n",
      "Standard Deviation of R2: 0.186\n"
     ]
    }
   ],
   "source": [
    "# Define the number of folds for cross-validation\n",
    "n_folds = 10\n",
    "\n",
    "# Initialize an empty list to store RMSE scores for each fold\n",
    "rmse_scores = []\n",
    "r2_scores = []\n",
    "\n",
    "# Create the KFold cross-validator\n",
    "kfold = KFold(n_splits=n_folds, shuffle=False)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Define the neural network model for regression\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim=X.shape[1], activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(1))  # Output layer for regression\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "# Perform 10-fold cross-validation\n",
    "for train_idx, test_idx in kfold.split(X):\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = Y[train_idx], Y[test_idx]\n",
    "    \n",
    "    # Create and train the model\n",
    "    model = create_model()\n",
    "    model.fit(X_train, y_train, validation_split=0.1, epochs=100, batch_size=32, verbose=0, callbacks=[early_stopping])\n",
    "    \n",
    "    # Evaluate the model on the test set and calculate RMSE\n",
    "    y_pred = model.predict(X_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    rmse_scores.append(rmse)\n",
    "    r2_scores.append(r2)\n",
    "\n",
    "# Convert the RMSE scores to a NumPy array for easier calculations\n",
    "rmse_scores = np.array(rmse_scores)\n",
    "r2_scores = np.array(r2_scores)\n",
    "\n",
    "# Calculate the mean and standard deviation of RMSE scores\n",
    "mean_rmse = np.mean(rmse_scores)\n",
    "std_rmse = np.std(rmse_scores)\n",
    "mean_r2 = np.mean(r2_scores)\n",
    "std_r2 = np.std(r2_scores)\n",
    "\n",
    "print('10-Fold Cross-Validation RMSE Scores:')\n",
    "print(rmse_scores)\n",
    "print('Mean RMSE: {:.3f}'.format(mean_rmse))\n",
    "print('Standard Deviation of RMSE: {:.3f}'.format(std_rmse))\n",
    "\n",
    "print('10-Fold Cross-Validation R2 Scores:')\n",
    "print(r2_scores)\n",
    "print('Mean R2: {:.3f}'.format(mean_r2))\n",
    "print('Standard Deviation of R2: {:.3f}'.format(std_r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "37c6b86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_regression_2 = df_regression.drop(columns=[\"MeanCO2_lv2\", \"MeanTotalGHG_lv2\"])\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "normalised_df_regression = scaler.fit_transform(df_regression_2)\n",
    "S1S2CO2e = normalised_df_regression[:, -1]\n",
    "\n",
    "# drop the label\n",
    "normalised_df_regression = np.delete(normalised_df_regression, -1, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6666b65b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(765, 37)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalised_df_regression.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3880c26e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instances in X: 765\n",
      "Number of instances in X_train: 535\n",
      "Number of instances in X_test: 230\n",
      "Number of instances in X_train and X_test together: 765\n"
     ]
    }
   ],
   "source": [
    "X = normalised_df_regression\n",
    "Y = S1S2CO2e\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, train_size=0.70, test_size=0.30, random_state=0)\n",
    "\n",
    "print('Number of instances in X: {}'.format(np.shape(X)[0]))\n",
    "print('Number of instances in X_train: {}'.format(X_train.shape[0]))\n",
    "print('Number of instances in X_test: {}'.format(X_test.shape[0]))\n",
    "print('Number of instances in X_train and X_test together: {}'.format(X_train.shape[0] + X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "280ceef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 313us/step\n",
      "Testing accuracy by using r2_score metric: 0.367\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Create a deep learning model\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1))  # Output layer for regression\n",
    "\n",
    "# Step 2: Compile the model\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "# Step 3: Train the model\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=32, verbose=0)\n",
    "\n",
    "# Step 4: Evaluate the model on testing data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Step 5: Calculate R-squared score\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print('Testing accuracy by using r2_score metric: {:.3f}'.format(r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "84f77478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 569us/step\n",
      "3/3 [==============================] - 0s 550us/step\n",
      "3/3 [==============================] - 0s 579us/step\n",
      "3/3 [==============================] - 0s 520us/step\n",
      "3/3 [==============================] - 0s 540us/step\n",
      "3/3 [==============================] - 0s 571us/step\n",
      "3/3 [==============================] - 0s 525us/step\n",
      "3/3 [==============================] - 0s 578us/step\n",
      "3/3 [==============================] - 0s 540us/step\n",
      "3/3 [==============================] - 0s 538us/step\n",
      "10-Fold Cross-Validation RMSE Scores:\n",
      "[0.1648126  0.0995914  0.1533695  0.16601439 0.18445325 0.09216998\n",
      " 0.04056146 0.10556389 0.07450672 0.10265761]\n",
      "Mean RMSE: 0.118\n",
      "Standard Deviation of RMSE: 0.044\n",
      "10-Fold Cross-Validation R2 Scores:\n",
      "[ 0.19925352  0.46478967 -0.03237498 -0.10581203  0.20561373  0.47631186\n",
      " -0.81157041  0.10248296  0.29355085  0.37122855]\n",
      "Mean R2: 0.116\n",
      "Standard Deviation of R2: 0.360\n"
     ]
    }
   ],
   "source": [
    "# Define the number of folds for cross-validation\n",
    "n_folds = 10\n",
    "\n",
    "# Initialize an empty list to store RMSE scores for each fold\n",
    "rmse_scores = []\n",
    "r2_scores = []\n",
    "\n",
    "# Create the KFold cross-validator\n",
    "kfold = KFold(n_splits=n_folds, shuffle=False)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Define the neural network model for regression\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim=X.shape[1], activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(1))  # Output layer for regression\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "# Perform 10-fold cross-validation\n",
    "for train_idx, test_idx in kfold.split(X):\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = Y[train_idx], Y[test_idx]\n",
    "    \n",
    "    # Create and train the model\n",
    "    model = create_model()\n",
    "    model.fit(X_train, y_train, validation_split=0.1, epochs=100, batch_size=32, verbose=0, callbacks=[early_stopping])\n",
    "    \n",
    "    # Evaluate the model on the test set and calculate RMSE\n",
    "    y_pred = model.predict(X_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    rmse_scores.append(rmse)\n",
    "    r2_scores.append(r2)\n",
    "\n",
    "# Convert the RMSE scores to a NumPy array for easier calculations\n",
    "rmse_scores = np.array(rmse_scores)\n",
    "r2_scores = np.array(r2_scores)\n",
    "\n",
    "# Calculate the mean and standard deviation of RMSE scores\n",
    "mean_rmse = np.mean(rmse_scores)\n",
    "std_rmse = np.std(rmse_scores)\n",
    "mean_r2 = np.mean(r2_scores)\n",
    "std_r2 = np.std(r2_scores)\n",
    "\n",
    "print('10-Fold Cross-Validation RMSE Scores:')\n",
    "print(rmse_scores)\n",
    "print('Mean RMSE: {:.3f}'.format(mean_rmse))\n",
    "print('Standard Deviation of RMSE: {:.3f}'.format(std_rmse))\n",
    "\n",
    "print('10-Fold Cross-Validation R2 Scores:')\n",
    "print(r2_scores)\n",
    "print('Mean R2: {:.3f}'.format(mean_r2))\n",
    "print('Standard Deviation of R2: {:.3f}'.format(std_r2))\n",
    "\n",
    "# Conclusion:\n",
    "# Random Forest was unable to learn the current pattern on level2 SIC dataset\n",
    "# 37 features with deep learning is not better than Random Forest Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788554e7",
   "metadata": {},
   "source": [
    "Autoencoder with df_regression 39 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "528dbb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "normalised_df_regression = scaler.fit_transform(df_regression)\n",
    "S1S2CO2e = normalised_df_regression[:, -1]\n",
    "\n",
    "# drop the label\n",
    "normalised_df_regression = np.delete(normalised_df_regression, -1, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1ea65e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instances in X: 765\n",
      "Number of instances in X_train: 535\n",
      "Number of instances in X_test: 230\n",
      "Number of instances in X_train and X_test together: 765\n"
     ]
    }
   ],
   "source": [
    "X = normalised_df_regression\n",
    "Y = S1S2CO2e\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, train_size=0.70, test_size=0.30, random_state=0)\n",
    "\n",
    "print('Number of instances in X: {}'.format(np.shape(X)[0]))\n",
    "print('Number of instances in X_train: {}'.format(X_train.shape[0]))\n",
    "print('Number of instances in X_test: {}'.format(X_test.shape[0]))\n",
    "print('Number of instances in X_train and X_test together: {}'.format(X_train.shape[0] + X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "119d5ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input layer\n",
    "input_layer = Input(shape=(X_train.shape[1],))\n",
    "latent_feature = 5\n",
    "\n",
    "# Encoder layers\n",
    "encoder_layer1 = Dense(64, activation='relu')(input_layer)\n",
    "encoder_layer2 = Dense(32, activation='relu')(encoder_layer1)\n",
    "encoder_output = Dense(latent_feature, activation='relu')(encoder_layer2)  # Latent view\n",
    "\n",
    "# Decoder layers\n",
    "decoder_layer1 = Dense(32, activation='relu')(encoder_output)\n",
    "decoder_layer2 = Dense(64, activation='relu')(decoder_layer1)\n",
    "decoder_output = Dense(X_train.shape[1], activation='sigmoid')(decoder_layer2)\n",
    "\n",
    "# Compile the autoencoder\n",
    "autoencoder = Model(inputs=input_layer, outputs=decoder_output)\n",
    "autoencoder.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9edaf53c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x29a6d10c0>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.fit(X_train, X_train, epochs=100, batch_size=32, validation_data=(X_test, X_test), verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f57ed8ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 384us/step\n",
      "8/8 [==============================] - 0s 339us/step\n"
     ]
    }
   ],
   "source": [
    "encoder = Model(inputs=input_layer, outputs=encoder_output)\n",
    "encoded_data = encoder.predict(X_train)\n",
    "encoded_data_test = encoder.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8fea3ddd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(535, 5)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f7ec5188",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(230, 5)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_data_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3ee33c94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(765, 5)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_encoded_data = np.concatenate([encoded_data, encoded_data_test], axis=0)\n",
    "combined_encoded_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bd5f376b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(765, 44)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_with_ae = np.concatenate([normalised_df_regression, combined_encoded_data], axis=1)\n",
    "features_with_ae.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4dcd6e",
   "metadata": {},
   "source": [
    "Random Forest + Autoencoder Latent Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ee312efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instances in X: 765\n",
      "Number of instances in X_train: 535\n",
      "Number of instances in X_test: 230\n",
      "Number of instances in X_train and X_test together: 765\n"
     ]
    }
   ],
   "source": [
    "X = features_with_ae\n",
    "Y = S1S2CO2e\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, train_size=0.70, test_size=0.30, random_state=0)\n",
    "\n",
    "print('Number of instances in X: {}'.format(np.shape(X)[0]))\n",
    "print('Number of instances in X_train: {}'.format(X_train.shape[0]))\n",
    "print('Number of instances in X_test: {}'.format(X_test.shape[0]))\n",
    "print('Number of instances in X_train and X_test together: {}'.format(X_train.shape[0] + X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0fbb0dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.911\n",
      "Testing accuracy by using score function: 0.459\n",
      "Testing accuracy by using r2_score meric: 0.459\n"
     ]
    }
   ],
   "source": [
    "rf_regressor = RandomForestRegressor()\n",
    "rf_regressor.fit(X_train, y_train)\n",
    "print('Training accuracy: {:.3f}'.format(rf_regressor.score(X_train, y_train)))\n",
    "\n",
    "print('Testing accuracy by using score function: {:.3f}'.format(rf_regressor.score(X_test, y_test)))\n",
    "print('Testing accuracy by using r2_score meric: {:.3f}'.format(r2_score(y_test, rf_regressor.predict(X_test))))\n",
    "# Generalise better with autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2a02304b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores:  [ 0.47625922  0.51899251  0.65881778  0.26841997  0.30253563 -0.41000843\n",
      "  0.16154432  0.25793221  0.27282291  0.23787439]\n",
      "Mean cross-validation score: 0.275\n"
     ]
    }
   ],
   "source": [
    "# perform 10-fold cross-validation\n",
    "cv_scores = cross_val_score(rf_regressor, X_train, y_train, cv=10)\n",
    "\n",
    "# print the cross-validation scores\n",
    "print('Cross-validation scores: ', cv_scores)\n",
    "\n",
    "# print the mean of the cross-validation scores\n",
    "print('Mean cross-validation score: {:.3f}'.format(np.mean(cv_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7faba8cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error train: 0.041\n",
      "Root Mean Squared Error test: 0.068\n"
     ]
    }
   ],
   "source": [
    "# make predictions on the test set\n",
    "y_pred = rf_regressor.predict(X_test)\n",
    "y_pred_train = rf_regressor.predict(X_train)\n",
    "\n",
    "# calculate the RMSE\n",
    "rmse_train = mean_squared_error(y_train, y_pred_train, squared=False)\n",
    "print('Root Mean Squared Error train: {:.3f}'.format(rmse_train))\n",
    "\n",
    "rmse_test = mean_squared_error(y_test, y_pred, squared=False)\n",
    "print('Root Mean Squared Error test: {:.3f}'.format(rmse_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "48d9c825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-Fold Cross-Validation RMSE Scores:\n",
      "[0.15297852 0.09416954 0.14026914 0.13605869 0.14516836 0.10254629\n",
      " 0.03345247 0.07130735 0.06373305 0.06824425]\n",
      "Mean RMSE: 0.101\n",
      "Standard Deviation of RMSE: 0.039\n",
      "10-Fold Cross-Validation R2 Scores:\n",
      "[ 0.31011746  0.52147826  0.13645745  0.2572504   0.50795702  0.35176329\n",
      " -0.23220982  0.59047493  0.48308466  0.72212939]\n",
      "Mean R2: 0.365\n",
      "Standard Deviation of R2: 0.257\n"
     ]
    }
   ],
   "source": [
    "# Define the number of folds for cross-validation\n",
    "n_folds = 10\n",
    "\n",
    "# Initialize an empty list to store RMSE scores for each fold\n",
    "rmse_scores = []\n",
    "r2_scores = []\n",
    "\n",
    "# Create the KFold cross-validator\n",
    "kfold = KFold(n_splits=n_folds, shuffle=False)\n",
    "\n",
    "# Perform 10-fold cross-validation\n",
    "for train_idx, test_idx in kfold.split(X):\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = Y[train_idx], Y[test_idx]\n",
    "    \n",
    "    # Create and train the model\n",
    "    rf_regressor.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate the model on the test set and calculate RMSE\n",
    "    y_pred = rf_regressor.predict(X_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    rmse_scores.append(rmse)\n",
    "    r2_scores.append(r2)\n",
    "\n",
    "# Convert the RMSE scores to a NumPy array for easier calculations\n",
    "rmse_scores = np.array(rmse_scores)\n",
    "r2_scores = np.array(r2_scores)\n",
    "\n",
    "# Calculate the mean and standard deviation of RMSE scores\n",
    "mean_rmse = np.mean(rmse_scores)\n",
    "std_rmse = np.std(rmse_scores)\n",
    "mean_r2 = np.mean(r2_scores)\n",
    "std_r2 = np.std(r2_scores)\n",
    "\n",
    "print('10-Fold Cross-Validation RMSE Scores:')\n",
    "print(rmse_scores)\n",
    "print('Mean RMSE: {:.3f}'.format(mean_rmse))\n",
    "print('Standard Deviation of RMSE: {:.3f}'.format(std_rmse))\n",
    "\n",
    "print('10-Fold Cross-Validation R2 Scores:')\n",
    "print(r2_scores)\n",
    "print('Mean R2: {:.3f}'.format(mean_r2))\n",
    "print('Standard Deviation of R2: {:.3f}'.format(std_r2))\n",
    "# Conclusion: RF with autoencoders does not improve the RMSE but improves the R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8cf12db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = df_regression.columns.tolist()\n",
    "features_list = features_list[:-1]\n",
    "features_list.append(\"ae1\")\n",
    "features_list.append(\"ae2\")\n",
    "features_list.append(\"ae3\")\n",
    "features_list.append(\"ae4\")\n",
    "features_list.append(\"ae5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8f0135ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: AssetsM, Score: 0.13695947928466687\n",
      "Feature: TurnoverM, Score: 0.1789549599045201\n",
      "Feature: FTE, Score: 0.16062131953557615\n",
      "Feature: IR_CO2ePerAssetsM, Score: 0.011897639716368414\n",
      "Feature: IR_CO2ePerTurnoverM, Score: 0.07824847087070727\n",
      "Feature: IR_CO2ePerFTE, Score: 0.056906654570662886\n",
      "Feature: DefraRatio, Score: 0.01639571556726516\n",
      "Feature: NormalisedIrCO2ePerAssetsM, Score: 0.0\n",
      "Feature: NormalisedIrCO2ePerTurnoverM, Score: 0.0\n",
      "Feature: NormalisedIrCO2ePerFTE, Score: 0.0\n",
      "Feature: ScoreC1a, Score: 0.00613752615397977\n",
      "Feature: ScoreC1t, Score: 0.006193169739855543\n",
      "Feature: ScoreC1f, Score: 0.021643930442679263\n",
      "Feature: ScoreC2, Score: 0.004560209425790763\n",
      "Feature: ScoreC1, Score: 0.013074859352652308\n",
      "Feature: MeanTotalGHG, Score: 0.0019219811384758867\n",
      "Feature: MeanCO2, Score: 0.004583575381730327\n",
      "Feature: MeanCH4, Score: 0.0033606210528798275\n",
      "Feature: MeanN2O, Score: 0.0068892762495733366\n",
      "Feature: MeanHFC, Score: 0.022428434177160825\n",
      "Feature: MeanPFC, Score: 0.004400385221005326\n",
      "Feature: MeanNF3, Score: 0.00247106023392557\n",
      "Feature: MeanSF6, Score: 0.005115133299297372\n",
      "Feature: GHGIntensity, Score: 0.004831937326695503\n",
      "Feature: CO2Intensity, Score: 0.0016075512902923817\n",
      "Feature: PM10, Score: 0.00411267124014519\n",
      "Feature: PM25, Score: 0.0032614815038807606\n",
      "Feature: CO, Score: 0.004824054104458682\n",
      "Feature: NMVOC, Score: 0.012777249422984263\n",
      "Feature: Benzene, Score: 0.00331561031785578\n",
      "Feature: Butadine, Score: 0.003239022352589752\n",
      "Feature: EnergyIntensity, Score: 0.0037939872746849744\n",
      "Feature: Electricity, Score: 0.0009776802391109846\n",
      "Feature: Petrol/diesel, Score: 0.0014498576907841707\n",
      "Feature: Natural gas, Score: 0.0006356033922733689\n",
      "Feature: OtherEenergy, Score: 0.011887521858578545\n",
      "Feature: EnergyTotal, Score: 0.0011206608199902323\n",
      "Feature: MeanTotalGHG_lv2, Score: 0.012964600312018862\n",
      "Feature: MeanCO2_lv2, Score: 0.005595480982222595\n",
      "Feature: ae1, Score: 0.04012668494406561\n",
      "Feature: ae2, Score: 0.03743719268250812\n",
      "Feature: ae3, Score: 0.04631604848180945\n",
      "Feature: ae4, Score: 0.025922354775351007\n",
      "Feature: ae5, Score: 0.031038347668926727\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarise feature importance\n",
    "for i,v in enumerate(rf_regressor.feature_importances_):\n",
    "    print(f\"Feature: {features_list[i]}, Score: {v}\")\n",
    "\n",
    "# plot feature importance\n",
    "plt.bar([x for x in range(len(rf_regressor.feature_importances_))], rf_regressor.feature_importances_)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7058db43",
   "metadata": {},
   "source": [
    "Conclusion:\n",
    "Autoencoders learnt some pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c88ef14",
   "metadata": {},
   "source": [
    "======================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ba778fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The R2 score is 0.9227\n",
      "\n",
      "RMSE train is 0.0356\n",
      "\n",
      "RMSE test is 0.1153\n",
      "(765, 1035)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "# Polynomial feature\n",
    "\n",
    "def polynomial_regression(X, y):\n",
    "\n",
    "    poly = PolynomialFeatures(2)\n",
    "    X_poly = poly.fit_transform(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_poly, y, train_size=0.7, test_size=0.3, random_state=0)\n",
    "    \n",
    "    # Fitting the model\n",
    "    rf = RandomForestRegressor()\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred_train = rf.predict(X_train)\n",
    "    y_pred_test = rf.predict(X_test)\n",
    "\n",
    "    rmse_train = mean_squared_error(y_train, y_pred_train, squared=False)\n",
    "    rmse_test = mean_squared_error(y_test, y_pred_test, squared=False)\n",
    "    \n",
    "    print(f\"\\nThe R2 score is {rf.score(X_train, y_train):.4f}\")\n",
    "\n",
    "    print(f\"\\nRMSE train is {rmse_train:.4f}\")\n",
    "    print(f\"\\nRMSE test is {rmse_test:.4f}\")\n",
    "    \n",
    "    print(X_poly.shape)\n",
    "    \n",
    "polynomial_regression(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81af29e",
   "metadata": {},
   "source": [
    "Compared the above result with non polynomial:\n",
    "Root Mean Squared Error test: 0.041\n",
    "Root Mean Squared Error test: 0.068\n",
    "\n",
    "R2 scores improved"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
